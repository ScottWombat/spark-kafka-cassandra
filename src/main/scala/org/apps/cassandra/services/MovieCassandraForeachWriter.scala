package org.apps.cassandra.services
import org.apps.cassandra.model.Movie
import com.datastax.spark.connector.cql.CassandraConnector
import org.apache.spark.sql.{ForeachWriter, SparkSession}

/**
  * CarCassandraForeachWriter Class extending ForeachWriter abstract class
  * and implementing its three abstract method open, process and close for
  * writing custom logic to process data generated by a query.
  * It also extends Logging Trait to add loggers.
  */
class MovieCassandraForeachWriter(spark: SparkSession) extends ForeachWriter[Movie] {

  /*
    - on every batch, on every partition `partitionId`
      - on every "epoch" = chunk of data
        - call the open method; if false, skip this chunk
        - for each entry in this chunk, call the process method
        - call the close method either at the end of the chunk or with an error if it was thrown
   */

  val keyspace = "my_keyspace"
  val table = "movies"
  val connector: CassandraConnector = CassandraConnector(spark.sparkContext.getConf
    .set("spark.cassandra.connection.host", "192.168.62.218")
    .set("spark.cassandra.connection.port", "9042")
    .set("spark.sql.extensions", "com.datastax.spark.connector.CassandraSparkExtensions")
  )

  override def open(partitionId: Long, epochId: Long): Boolean = {
    println("Open connection.")
    true
  }

  override def process(movie: Movie): Unit = {

    // Executing insert query to cassandraDB via CassandraConnector.
    connector.withSessionDo { session =>
      session.execute(s"insert into my_keyspace.movies(id,duration,rating,title,year) values(${movie.id},${movie.duration},${movie.rating},'${movie.title}',${movie.year})")
      
    }
  }

  override def close(errorOrNull: Throwable): Unit = println("Closing connection.")

}